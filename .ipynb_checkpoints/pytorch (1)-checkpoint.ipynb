{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db13f5d6",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ae2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f93fe",
   "metadata": {},
   "source": [
    "### Extra files from torchmetrics to carry out performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b737e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.functional import auc\n",
    "from torchmetrics import Precision\n",
    "from torchmetrics import Recall\n",
    "from torchmetrics import ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203aa5a7",
   "metadata": {},
   "source": [
    "### Load images from net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3fc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "# download_url(data_url, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59795d47",
   "metadata": {},
   "source": [
    "## Extract data by unzipping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027d59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "#     tar.extractall(path='./mydataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08baa1e",
   "metadata": {},
   "source": [
    "### Create my project dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03f975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder('./mydataset/cifar10/train', transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511cfe52",
   "metadata": {},
   "source": [
    "### Dividing data into train,test and validation set of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d8cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_seed = 42\n",
    "torch.manual_seed(r_seed);\n",
    "vsize = 5000\n",
    "tsize = len(dataset) - vsize\n",
    "\n",
    "train_dataset, validation_ds = random_split(dataset, [tsize, vsize])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828839e",
   "metadata": {},
   "source": [
    "### Creating data loaders for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702e634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(validation_ds, batch_size*2, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961bfb5",
   "metadata": {},
   "source": [
    "### Creating NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a881301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc98340",
   "metadata": {},
   "source": [
    "### checking the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db1cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd43bc",
   "metadata": {},
   "source": [
    "### passing the model to a device, this is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa99b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc978aea",
   "metadata": {},
   "source": [
    "### Training and validation and finally evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8f7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fae80",
   "metadata": {},
   "source": [
    "### Displaying CNN model that we created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a823b",
   "metadata": {},
   "source": [
    "### Evaluating the CNN model that we build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291bea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "##evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2690ba",
   "metadata": {},
   "source": [
    "### Initializing hyperparameters to be used. We can change one at a time and talk about it in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed50f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "lr = 0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057cc8f",
   "metadata": {},
   "source": [
    "### Displaying the training accuracy, for every change of the hyperparameter in the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0233824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() #to know the size of the model i have\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)#calculate loss function(predected, actual)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(\"Loss \", loss, \" Current \", batch, \" of \", size/64)\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) \n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(\"Accuracy \", 100*correct, \" % \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058e6f6",
   "metadata": {},
   "source": [
    "### Method to predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06cc09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Loss  2.305856704711914  Current  0  of  703.125\n",
      "Loss  2.3133740425109863  Current  100  of  703.125\n",
      "Loss  2.3201889991760254  Current  200  of  703.125\n",
      "Loss  2.3122572898864746  Current  300  of  703.125\n",
      "Loss  2.307636260986328  Current  400  of  703.125\n",
      "Loss  2.322425365447998  Current  500  of  703.125\n",
      "Loss  2.30604887008667  Current  600  of  703.125\n",
      "Loss  2.273681163787842  Current  700  of  703.125\n",
      "Loss  2.25884747505188  Current  800  of  703.125\n",
      "Loss  2.298516273498535  Current  900  of  703.125\n",
      "Loss  2.2701754570007324  Current  1000  of  703.125\n",
      "Loss  2.3454794883728027  Current  1100  of  703.125\n",
      "Loss  2.2794456481933594  Current  1200  of  703.125\n",
      "Loss  2.335714340209961  Current  1300  of  703.125\n",
      "Loss  2.3407397270202637  Current  1400  of  703.125\n",
      "Loss  2.317222833633423  Current  1500  of  703.125\n",
      "Loss  2.293973445892334  Current  1600  of  703.125\n",
      "Loss  2.305086135864258  Current  1700  of  703.125\n",
      "Loss  2.3299293518066406  Current  1800  of  703.125\n",
      "Loss  2.3399975299835205  Current  1900  of  703.125\n",
      "Loss  2.3139801025390625  Current  2000  of  703.125\n",
      "Loss  2.330028533935547  Current  2100  of  703.125\n",
      "Loss  2.2907137870788574  Current  2200  of  703.125\n",
      "Loss  2.285701274871826  Current  2300  of  703.125\n",
      "Loss  2.2967543601989746  Current  2400  of  703.125\n",
      "Loss  2.310750961303711  Current  2500  of  703.125\n",
      "Loss  2.3226675987243652  Current  2600  of  703.125\n",
      "Loss  2.311296224594116  Current  2700  of  703.125\n",
      "Loss  2.3063268661499023  Current  2800  of  703.125\n",
      "Loss  2.3176028728485107  Current  2900  of  703.125\n",
      "Loss  2.2782034873962402  Current  3000  of  703.125\n",
      "Loss  2.288577079772949  Current  3100  of  703.125\n",
      "Loss  2.332690954208374  Current  3200  of  703.125\n",
      "Loss  2.2984492778778076  Current  3300  of  703.125\n",
      "Loss  2.2998545169830322  Current  3400  of  703.125\n",
      "Loss  2.29477596282959  Current  3500  of  703.125\n",
      "Loss  2.283315420150757  Current  3600  of  703.125\n",
      "Loss  2.2911629676818848  Current  3700  of  703.125\n",
      "Loss  2.311002254486084  Current  3800  of  703.125\n",
      "Loss  2.278568744659424  Current  3900  of  703.125\n",
      "Loss  2.3141744136810303  Current  4000  of  703.125\n",
      "Loss  2.3273401260375977  Current  4100  of  703.125\n",
      "Loss  2.3093738555908203  Current  4200  of  703.125\n",
      "Loss  2.280189037322998  Current  4300  of  703.125\n",
      "Loss  2.31318998336792  Current  4400  of  703.125\n",
      "Loss  2.335391044616699  Current  4500  of  703.125\n",
      "Loss  2.3282670974731445  Current  4600  of  703.125\n",
      "Loss  2.316256523132324  Current  4700  of  703.125\n",
      "Loss  2.31679105758667  Current  4800  of  703.125\n",
      "Loss  2.322044610977173  Current  4900  of  703.125\n",
      "Loss  2.2576851844787598  Current  5000  of  703.125\n",
      "Loss  2.373549699783325  Current  5100  of  703.125\n",
      "Loss  2.3395333290100098  Current  5200  of  703.125\n",
      "Loss  2.3435773849487305  Current  5300  of  703.125\n",
      "Loss  2.310863733291626  Current  5400  of  703.125\n",
      "Loss  2.304842710494995  Current  5500  of  703.125\n",
      "Loss  2.3097994327545166  Current  5600  of  703.125\n",
      "Loss  2.311485528945923  Current  5700  of  703.125\n",
      "Loss  2.303813934326172  Current  5800  of  703.125\n",
      "Loss  2.2951712608337402  Current  5900  of  703.125\n",
      "Loss  2.3102834224700928  Current  6000  of  703.125\n",
      "Loss  2.307004928588867  Current  6100  of  703.125\n",
      "Loss  2.292219877243042  Current  6200  of  703.125\n",
      "Loss  2.309234619140625  Current  6300  of  703.125\n",
      "Loss  2.2939720153808594  Current  6400  of  703.125\n",
      "Loss  2.2931885719299316  Current  6500  of  703.125\n",
      "Loss  2.31294322013855  Current  6600  of  703.125\n",
      "Loss  2.3108701705932617  Current  6700  of  703.125\n",
      "Loss  2.327526569366455  Current  6800  of  703.125\n",
      "Loss  2.285379409790039  Current  6900  of  703.125\n",
      "Loss  2.3142588138580322  Current  7000  of  703.125\n",
      "Loss  2.2846076488494873  Current  7100  of  703.125\n",
      "Loss  2.3062987327575684  Current  7200  of  703.125\n",
      "Loss  2.2849059104919434  Current  7300  of  703.125\n",
      "Loss  2.2891016006469727  Current  7400  of  703.125\n",
      "Loss  2.275485038757324  Current  7500  of  703.125\n",
      "Loss  2.270252227783203  Current  7600  of  703.125\n",
      "Loss  2.278029441833496  Current  7700  of  703.125\n",
      "Loss  2.299866199493408  Current  7800  of  703.125\n",
      "Loss  2.2815208435058594  Current  7900  of  703.125\n",
      "Loss  2.2779507637023926  Current  8000  of  703.125\n",
      "Loss  2.2996909618377686  Current  8100  of  703.125\n",
      "Loss  2.308347702026367  Current  8200  of  703.125\n",
      "Loss  2.3176612854003906  Current  8300  of  703.125\n",
      "Loss  2.344330072402954  Current  8400  of  703.125\n",
      "Loss  2.305041790008545  Current  8500  of  703.125\n",
      "Loss  2.2991068363189697  Current  8600  of  703.125\n",
      "Loss  2.3209586143493652  Current  8700  of  703.125\n",
      "Loss  2.306431293487549  Current  8800  of  703.125\n",
      "Loss  2.3073768615722656  Current  8900  of  703.125\n",
      "Loss  2.300360918045044  Current  9000  of  703.125\n",
      "Loss  2.323465347290039  Current  9100  of  703.125\n",
      "Loss  2.2986702919006348  Current  9200  of  703.125\n",
      "Loss  2.3114523887634277  Current  9300  of  703.125\n",
      "Loss  2.3162283897399902  Current  9400  of  703.125\n",
      "Loss  2.316472053527832  Current  9500  of  703.125\n",
      "Loss  2.2805557250976562  Current  9600  of  703.125\n",
      "Loss  2.326399087905884  Current  9700  of  703.125\n",
      "Loss  2.310659885406494  Current  9800  of  703.125\n",
      "Loss  2.275062322616577  Current  9900  of  703.125\n",
      "Loss  2.254331350326538  Current  10000  of  703.125\n",
      "Loss  2.2747340202331543  Current  10100  of  703.125\n",
      "Loss  2.3597512245178223  Current  10200  of  703.125\n",
      "Loss  2.3098723888397217  Current  10300  of  703.125\n",
      "Loss  2.324122190475464  Current  10400  of  703.125\n",
      "Loss  2.274907112121582  Current  10500  of  703.125\n",
      "Loss  2.2830257415771484  Current  10600  of  703.125\n",
      "Loss  2.299743890762329  Current  10700  of  703.125\n",
      "Loss  2.3037147521972656  Current  10800  of  703.125\n",
      "Loss  2.306924819946289  Current  10900  of  703.125\n",
      "Loss  2.3239455223083496  Current  11000  of  703.125\n",
      "Loss  2.288062572479248  Current  11100  of  703.125\n",
      "Loss  2.3208041191101074  Current  11200  of  703.125\n",
      "Loss  2.310215950012207  Current  11300  of  703.125\n",
      "Loss  2.300994873046875  Current  11400  of  703.125\n",
      "Loss  2.322925567626953  Current  11500  of  703.125\n",
      "Loss  2.2944164276123047  Current  11600  of  703.125\n",
      "Loss  2.295675754547119  Current  11700  of  703.125\n",
      "Loss  2.2955985069274902  Current  11800  of  703.125\n",
      "Loss  2.2933108806610107  Current  11900  of  703.125\n",
      "Loss  2.3139286041259766  Current  12000  of  703.125\n",
      "Loss  2.273749589920044  Current  12100  of  703.125\n",
      "Loss  2.3213143348693848  Current  12200  of  703.125\n",
      "Loss  2.3014376163482666  Current  12300  of  703.125\n",
      "Loss  2.3014392852783203  Current  12400  of  703.125\n",
      "Loss  2.3265678882598877  Current  12500  of  703.125\n",
      "Loss  2.281254291534424  Current  12600  of  703.125\n",
      "Loss  2.2780730724334717  Current  12700  of  703.125\n",
      "Loss  2.2995853424072266  Current  12800  of  703.125\n",
      "Loss  2.3297390937805176  Current  12900  of  703.125\n",
      "Loss  2.3068490028381348  Current  13000  of  703.125\n",
      "Loss  2.290581703186035  Current  13100  of  703.125\n",
      "Loss  2.2869269847869873  Current  13200  of  703.125\n",
      "Loss  2.3024325370788574  Current  13300  of  703.125\n",
      "Loss  2.3102848529815674  Current  13400  of  703.125\n",
      "Loss  2.3097023963928223  Current  13500  of  703.125\n",
      "Loss  2.288792610168457  Current  13600  of  703.125\n",
      "Loss  2.2827863693237305  Current  13700  of  703.125\n",
      "Loss  2.3161697387695312  Current  13800  of  703.125\n",
      "Loss  2.2951819896698  Current  13900  of  703.125\n",
      "Loss  2.2875685691833496  Current  14000  of  703.125\n",
      "Loss  2.3085598945617676  Current  14100  of  703.125\n",
      "Loss  2.3023133277893066  Current  14200  of  703.125\n",
      "Loss  2.317314386367798  Current  14300  of  703.125\n",
      "Loss  2.2895002365112305  Current  14400  of  703.125\n",
      "Loss  2.3189024925231934  Current  14500  of  703.125\n",
      "Loss  2.3114173412323  Current  14600  of  703.125\n",
      "Loss  2.2889976501464844  Current  14700  of  703.125\n",
      "Loss  2.3122434616088867  Current  14800  of  703.125\n",
      "Loss  2.325368881225586  Current  14900  of  703.125\n",
      "Loss  2.3231282234191895  Current  15000  of  703.125\n",
      "Loss  2.3281564712524414  Current  15100  of  703.125\n",
      "Loss  2.3240585327148438  Current  15200  of  703.125\n",
      "Loss  2.3131134510040283  Current  15300  of  703.125\n",
      "Loss  2.300464630126953  Current  15400  of  703.125\n",
      "Loss  2.30734920501709  Current  15500  of  703.125\n",
      "Loss  2.28057861328125  Current  15600  of  703.125\n",
      "Loss  2.3382742404937744  Current  15700  of  703.125\n",
      "Loss  2.3263144493103027  Current  15800  of  703.125\n",
      "Loss  2.3339836597442627  Current  15900  of  703.125\n",
      "Loss  2.302494525909424  Current  16000  of  703.125\n",
      "Loss  2.3345909118652344  Current  16100  of  703.125\n",
      "Loss  2.315481185913086  Current  16200  of  703.125\n",
      "Loss  2.3355019092559814  Current  16300  of  703.125\n",
      "Loss  2.295957326889038  Current  16400  of  703.125\n",
      "Loss  2.2962591648101807  Current  16500  of  703.125\n",
      "Loss  2.2952804565429688  Current  16600  of  703.125\n",
      "Loss  2.3165764808654785  Current  16700  of  703.125\n",
      "Loss  2.324862480163574  Current  16800  of  703.125\n",
      "Loss  2.308858633041382  Current  16900  of  703.125\n",
      "Loss  2.3020615577697754  Current  17000  of  703.125\n",
      "Loss  2.3041210174560547  Current  17100  of  703.125\n",
      "Loss  2.31093692779541  Current  17200  of  703.125\n",
      "Loss  2.3146984577178955  Current  17300  of  703.125\n",
      "Loss  2.2976114749908447  Current  17400  of  703.125\n",
      "Loss  2.31504487991333  Current  17500  of  703.125\n",
      "Loss  2.292405605316162  Current  17600  of  703.125\n",
      "Loss  2.330227851867676  Current  17700  of  703.125\n",
      "Loss  2.3334224224090576  Current  17800  of  703.125\n",
      "Loss  2.306011199951172  Current  17900  of  703.125\n",
      "Loss  2.329509735107422  Current  18000  of  703.125\n",
      "Loss  2.293067455291748  Current  18100  of  703.125\n",
      "Loss  2.2922263145446777  Current  18200  of  703.125\n",
      "Loss  2.2760674953460693  Current  18300  of  703.125\n",
      "Loss  2.3437581062316895  Current  18400  of  703.125\n",
      "Loss  2.3078222274780273  Current  18500  of  703.125\n",
      "Loss  2.3074545860290527  Current  18600  of  703.125\n",
      "Loss  2.3224802017211914  Current  18700  of  703.125\n",
      "Loss  2.2770962715148926  Current  18800  of  703.125\n",
      "Loss  2.313142776489258  Current  18900  of  703.125\n",
      "Loss  2.321061849594116  Current  19000  of  703.125\n",
      "Loss  2.2833850383758545  Current  19100  of  703.125\n",
      "Loss  2.2834346294403076  Current  19200  of  703.125\n",
      "Loss  2.305623769760132  Current  19300  of  703.125\n",
      "Loss  2.2939488887786865  Current  19400  of  703.125\n",
      "Loss  2.3286290168762207  Current  19500  of  703.125\n",
      "Loss  2.268733024597168  Current  19600  of  703.125\n",
      "Loss  2.298039197921753  Current  19700  of  703.125\n",
      "Loss  2.2831897735595703  Current  19800  of  703.125\n",
      "Loss  2.3008718490600586  Current  19900  of  703.125\n",
      "Loss  2.351658582687378  Current  20000  of  703.125\n",
      "Loss  2.348613977432251  Current  20100  of  703.125\n",
      "Loss  2.351733446121216  Current  20200  of  703.125\n",
      "Loss  2.315342664718628  Current  20300  of  703.125\n",
      "Loss  2.304309368133545  Current  20400  of  703.125\n",
      "Loss  2.3098649978637695  Current  20500  of  703.125\n",
      "Loss  2.28692626953125  Current  20600  of  703.125\n",
      "Loss  2.2969858646392822  Current  20700  of  703.125\n",
      "Loss  2.312044143676758  Current  20800  of  703.125\n",
      "Loss  2.299114227294922  Current  20900  of  703.125\n",
      "Loss  2.2873964309692383  Current  21000  of  703.125\n",
      "Loss  2.310610771179199  Current  21100  of  703.125\n",
      "Loss  2.2865653038024902  Current  21200  of  703.125\n",
      "Loss  2.297464609146118  Current  21300  of  703.125\n",
      "Loss  2.315365791320801  Current  21400  of  703.125\n",
      "Loss  2.3403310775756836  Current  21500  of  703.125\n",
      "Loss  2.294997215270996  Current  21600  of  703.125\n",
      "Loss  2.3023252487182617  Current  21700  of  703.125\n",
      "Loss  2.326251983642578  Current  21800  of  703.125\n",
      "Loss  2.313220739364624  Current  21900  of  703.125\n",
      "Loss  2.2901344299316406  Current  22000  of  703.125\n",
      "Loss  2.3699772357940674  Current  22100  of  703.125\n",
      "Loss  2.292161464691162  Current  22200  of  703.125\n",
      "Loss  2.3402516841888428  Current  22300  of  703.125\n",
      "Loss  2.3173773288726807  Current  22400  of  703.125\n",
      "Accuracy  9.6  % \n"
     ]
    }
   ],
   "source": [
    "epoches=1\n",
    "for t in range(epoches):\n",
    "    print(\"Epoch \", t)\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "torch.save(model.state_dict(), \"model.pth\") #this saves my model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4c8d7",
   "metadata": {},
   "source": [
    "### Creating a test using the model that we have created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8402a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder('./mydataset/cifar10/test', transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0859a0f",
   "metadata": {},
   "source": [
    "### Method to predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d16975d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)l\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return dataset.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed94bf1",
   "metadata": {},
   "source": [
    "## using the first image to test the model that we have build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6c777cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: deer  Actual: airplane\n"
     ]
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "print('Predicted:', predict_image(img, model),' Actual:', dataset.classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40a2f6",
   "metadata": {},
   "source": [
    "### Performance metrics using \n",
    "#### Creating the predicted and the actual data to pass to torchmetrics tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dc28668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actaul=[]\n",
    "predicted=[]\n",
    "\n",
    "for i in range(10):\n",
    "    img, label = test_dataset[i]\n",
    "    #plt.imshow(img.permute(1, 2, 0))\n",
    "    a=dataset.classes[label]\n",
    "    b=predict_image(img, model)\n",
    "    if a == 'horse':\n",
    "        actaul.append(1)\n",
    "    elif a == 'airplane':\n",
    "        actaul.append(2)\n",
    "    elif a == 'automobile':\n",
    "        actaul.append(3)\n",
    "    elif a == 'cat':\n",
    "        actaul.append(4)\n",
    "    elif a == 'frog':\n",
    "        actaul.append(5)\n",
    "    elif a == 'dog':\n",
    "        actaul.append(6)\n",
    "    elif a == 'ship':\n",
    "        actaul.append(7)\n",
    "    elif a == 'deer':\n",
    "        actaul.append(8)\n",
    "    elif a == 'bird':\n",
    "        actaul.append(9)\n",
    "    else:\n",
    "        actaul.append(10)\n",
    "        \n",
    "    if b == 'horse':\n",
    "        predicted.append(1)\n",
    "    elif b == 'airplane':\n",
    "        predicted.append(2)\n",
    "    elif b == 'automobile':\n",
    "        predicted.append(3)\n",
    "    elif b == 'cat':\n",
    "        predicted.append(4)\n",
    "    elif b == 'frog':\n",
    "        predicted.append(5)\n",
    "    elif b == 'dog':\n",
    "        predicted.append(6)\n",
    "    elif b == 'ship':\n",
    "        predicted.append(7)\n",
    "    elif b == 'deer':\n",
    "        predicted.append(8)\n",
    "    elif b == 'bird':\n",
    "        predicted.append(9)\n",
    "    else:\n",
    "        predicted.append(10)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd359b",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34230b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.0\n",
      "AUC is : 0.0\n",
      "Precision is : 0.0\n",
      "Precision is : 0.0\n",
      "ROC is : 0.0\n",
      "TPR is : [0, 0]\n",
      "FPR is : [0.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LANGAT KIPNGENO ARON\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\LANGAT KIPNGENO ARON\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(actaul)\n",
    "p = torch.tensor(predicted)\n",
    "accuracy = Accuracy()\n",
    "x=accuracy(p, t)\n",
    "print(\"Accuracy is :\",accuracy(p, t).item())\n",
    "print(\"AUC is :\",auc(p, t).item())\n",
    "precision = Precision()\n",
    "print(\"Precision is :\",precision(p, t).item())\n",
    "recall = Recall()\n",
    "print(\"Precision is :\",recall(p, t).item())\n",
    "roc = ROC(pos_label=1)\n",
    "fpr, tpr, thresholds = roc(p, t)\n",
    "print(\"ROC is :\",recall(p, t).item())\n",
    "print(\"TPR is :\",tpr.tolist())\n",
    "print(\"FPR is :\",fpr.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
